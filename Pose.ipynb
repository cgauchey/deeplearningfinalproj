{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2, os, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = Path() / 'data' / 'SfM' / 'images'\n",
    "frames = None # TODO: load from directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our Pose model, modified ever so slightly from the implementation found at the GitHub link below. Its input is the raw images and its output is a 6DOF vector for every camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From https://github.com/fedeizzo/camera-pose-estimation/blob/master/camera-pose-estimation/model/models/mapnet.py\n",
    "\"\"\"\n",
    "\n",
    "class PoseNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_dimension: int, dropout_rate: float) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.feature_extractor = models.resnet34(pretrained=True) # TODO: something else?\n",
    "        self.feature_extractor.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        out_feature_extractor = self.feature_extractor.fc.in_features\n",
    "\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.feature_extractor.fc = nn.Sequential(\n",
    "            nn.Linear(out_feature_extractor, feature_dimension),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dimension, feature_dimension // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dimension // 2, feature_dimension // 4),\n",
    "        )\n",
    "\n",
    "        self.xyz_encoder = nn.Linear(feature_dimension // 4, 3)\n",
    "        self.wxyz_encoder = nn.Linear(feature_dimension // 4, 4)\n",
    "\n",
    "        init_modules = [\n",
    "            self.feature_extractor.fc,\n",
    "            self.xyz_encoder,\n",
    "            self.wxyz_encoder,\n",
    "        ]\n",
    "\n",
    "        for m in init_modules:\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input shape should be [(Batch*Steps) x Channels x Width x Height]\n",
    "        \"\"\"\n",
    "        x = self.feature_extractor(x)\n",
    "        x = F.relu(x)\n",
    "        if self.dropout_rate > 0:\n",
    "            x = F.dropout(x, p=self.dropout_rate)\n",
    "\n",
    "        xyz = self.xyz_encoder(x)\n",
    "        wxyz = self.wxyz_encoder(x)\n",
    "\n",
    "        return torch.cat((xyz, wxyz), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At present, we're using SfM sparse points from COLMAP as the supervisory signal. They were processed separately and are loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From https://github.com/graphdeco-inria/gaussian-splatting/blob/main/scene/colmap_loader.py\n",
    "\"\"\"\n",
    "\n",
    "#\n",
    "# Copyright (C) 2023, Inria\n",
    "# GRAPHDECO research group, https://team.inria.fr/graphdeco\n",
    "# All rights reserved.\n",
    "#\n",
    "# This software is free for non-commercial, research and evaluation use \n",
    "# under the terms of the LICENSE.md file.\n",
    "#\n",
    "# For inquiries contact  george.drettakis@inria.fr\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import struct\n",
    "\n",
    "CameraModel = collections.namedtuple(\n",
    "    \"CameraModel\", [\"model_id\", \"model_name\", \"num_params\"])\n",
    "Camera = collections.namedtuple(\n",
    "    \"Camera\", [\"id\", \"model\", \"width\", \"height\", \"params\"])\n",
    "BaseImage = collections.namedtuple(\n",
    "    \"Image\", [\"id\", \"qvec\", \"tvec\", \"camera_id\", \"name\", \"xys\", \"point3D_ids\"])\n",
    "Point3D = collections.namedtuple(\n",
    "    \"Point3D\", [\"id\", \"xyz\", \"rgb\", \"error\", \"image_ids\", \"point2D_idxs\"])\n",
    "CAMERA_MODELS = {\n",
    "    CameraModel(model_id=0, model_name=\"SIMPLE_PINHOLE\", num_params=3),\n",
    "    CameraModel(model_id=1, model_name=\"PINHOLE\", num_params=4),\n",
    "    CameraModel(model_id=2, model_name=\"SIMPLE_RADIAL\", num_params=4),\n",
    "    CameraModel(model_id=3, model_name=\"RADIAL\", num_params=5),\n",
    "    CameraModel(model_id=4, model_name=\"OPENCV\", num_params=8),\n",
    "    CameraModel(model_id=5, model_name=\"OPENCV_FISHEYE\", num_params=8),\n",
    "    CameraModel(model_id=6, model_name=\"FULL_OPENCV\", num_params=12),\n",
    "    CameraModel(model_id=7, model_name=\"FOV\", num_params=5),\n",
    "    CameraModel(model_id=8, model_name=\"SIMPLE_RADIAL_FISHEYE\", num_params=4),\n",
    "    CameraModel(model_id=9, model_name=\"RADIAL_FISHEYE\", num_params=5),\n",
    "    CameraModel(model_id=10, model_name=\"THIN_PRISM_FISHEYE\", num_params=12)\n",
    "}\n",
    "CAMERA_MODEL_IDS = dict([(camera_model.model_id, camera_model)\n",
    "                         for camera_model in CAMERA_MODELS])\n",
    "CAMERA_MODEL_NAMES = dict([(camera_model.model_name, camera_model)\n",
    "                           for camera_model in CAMERA_MODELS])\n",
    "\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])\n",
    "\n",
    "def rotmat2qvec(R):\n",
    "    Rxx, Ryx, Rzx, Rxy, Ryy, Rzy, Rxz, Ryz, Rzz = R.flat\n",
    "    K = np.array([\n",
    "        [Rxx - Ryy - Rzz, 0, 0, 0],\n",
    "        [Ryx + Rxy, Ryy - Rxx - Rzz, 0, 0],\n",
    "        [Rzx + Rxz, Rzy + Ryz, Rzz - Rxx - Ryy, 0],\n",
    "        [Ryz - Rzy, Rzx - Rxz, Rxy - Ryx, Rxx + Ryy + Rzz]]) / 3.0\n",
    "    eigvals, eigvecs = np.linalg.eigh(K)\n",
    "    qvec = eigvecs[[3, 0, 1, 2], np.argmax(eigvals)]\n",
    "    if qvec[0] < 0:\n",
    "        qvec *= -1\n",
    "    return qvec\n",
    "\n",
    "class Image(BaseImage):\n",
    "    def qvec2rotmat(self):\n",
    "        return qvec2rotmat(self.qvec)\n",
    "\n",
    "def read_next_bytes(fid, num_bytes, format_char_sequence, endian_character=\"<\"):\n",
    "    \"\"\"Read and unpack the next bytes from a binary file.\n",
    "    :param fid:\n",
    "    :param num_bytes: Sum of combination of {2, 4, 8}, e.g. 2, 6, 16, 30, etc.\n",
    "    :param format_char_sequence: List of {c, e, f, d, h, H, i, I, l, L, q, Q}.\n",
    "    :param endian_character: Any of {@, =, <, >, !}\n",
    "    :return: Tuple of read and unpacked values.\n",
    "    \"\"\"\n",
    "    data = fid.read(num_bytes)\n",
    "    return struct.unpack(endian_character + format_char_sequence, data)\n",
    "\n",
    "def read_points3D_text(path):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadPoints3DText(const std::string& path)\n",
    "        void Reconstruction::WritePoints3DText(const std::string& path)\n",
    "    \"\"\"\n",
    "    xyzs = None\n",
    "    rgbs = None\n",
    "    errors = None\n",
    "    num_points = 0\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                num_points += 1\n",
    "\n",
    "\n",
    "    xyzs = np.empty((num_points, 3))\n",
    "    rgbs = np.empty((num_points, 3))\n",
    "    errors = np.empty((num_points, 1))\n",
    "    count = 0\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                xyz = np.array(tuple(map(float, elems[1:4])))\n",
    "                rgb = np.array(tuple(map(int, elems[4:7])))\n",
    "                error = np.array(float(elems[7]))\n",
    "                xyzs[count] = xyz\n",
    "                rgbs[count] = rgb\n",
    "                errors[count] = error\n",
    "                count += 1\n",
    "\n",
    "    return xyzs, rgbs, errors\n",
    "\n",
    "def read_points3D_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadPoints3DBinary(const std::string& path)\n",
    "        void Reconstruction::WritePoints3DBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_points = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "\n",
    "        xyzs = np.empty((num_points, 3))\n",
    "        rgbs = np.empty((num_points, 3))\n",
    "        errors = np.empty((num_points, 1))\n",
    "\n",
    "        for p_id in range(num_points):\n",
    "            binary_point_line_properties = read_next_bytes(\n",
    "                fid, num_bytes=43, format_char_sequence=\"QdddBBBd\")\n",
    "            xyz = np.array(binary_point_line_properties[1:4])\n",
    "            rgb = np.array(binary_point_line_properties[4:7])\n",
    "            error = np.array(binary_point_line_properties[7])\n",
    "            track_length = read_next_bytes(\n",
    "                fid, num_bytes=8, format_char_sequence=\"Q\")[0]\n",
    "            track_elems = read_next_bytes(\n",
    "                fid, num_bytes=8*track_length,\n",
    "                format_char_sequence=\"ii\"*track_length)\n",
    "            xyzs[p_id] = xyz\n",
    "            rgbs[p_id] = rgb\n",
    "            errors[p_id] = error\n",
    "    return xyzs, rgbs, errors\n",
    "\n",
    "def read_intrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    cameras = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                camera_id = int(elems[0])\n",
    "                model = elems[1]\n",
    "                assert model == \"PINHOLE\", \"While the loader support other types, the rest of the code assumes PINHOLE\"\n",
    "                width = int(elems[2])\n",
    "                height = int(elems[3])\n",
    "                params = np.array(tuple(map(float, elems[4:])))\n",
    "                cameras[camera_id] = Camera(id=camera_id, model=model,\n",
    "                                            width=width, height=height,\n",
    "                                            params=params)\n",
    "    return cameras\n",
    "\n",
    "def read_extrinsics_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::ReadImagesBinary(const std::string& path)\n",
    "        void Reconstruction::WriteImagesBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_reg_images = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "        for _ in range(num_reg_images):\n",
    "            binary_image_properties = read_next_bytes(\n",
    "                fid, num_bytes=64, format_char_sequence=\"idddddddi\")\n",
    "            image_id = binary_image_properties[0]\n",
    "            qvec = np.array(binary_image_properties[1:5])\n",
    "            tvec = np.array(binary_image_properties[5:8])\n",
    "            camera_id = binary_image_properties[8]\n",
    "            image_name = \"\"\n",
    "            current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
    "            while current_char != b\"\\x00\":   # look for the ASCII 0 entry\n",
    "                image_name += current_char.decode(\"utf-8\")\n",
    "                current_char = read_next_bytes(fid, 1, \"c\")[0]\n",
    "            num_points2D = read_next_bytes(fid, num_bytes=8,\n",
    "                                           format_char_sequence=\"Q\")[0]\n",
    "            x_y_id_s = read_next_bytes(fid, num_bytes=24*num_points2D,\n",
    "                                       format_char_sequence=\"ddq\"*num_points2D)\n",
    "            xys = np.column_stack([tuple(map(float, x_y_id_s[0::3])),\n",
    "                                   tuple(map(float, x_y_id_s[1::3]))])\n",
    "            point3D_ids = np.array(tuple(map(int, x_y_id_s[2::3])))\n",
    "            images[image_id] = Image(\n",
    "                id=image_id, qvec=qvec, tvec=tvec,\n",
    "                camera_id=camera_id, name=image_name,\n",
    "                xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_intrinsics_binary(path_to_model_file):\n",
    "    \"\"\"\n",
    "    see: src/base/reconstruction.cc\n",
    "        void Reconstruction::WriteCamerasBinary(const std::string& path)\n",
    "        void Reconstruction::ReadCamerasBinary(const std::string& path)\n",
    "    \"\"\"\n",
    "    cameras = {}\n",
    "    with open(path_to_model_file, \"rb\") as fid:\n",
    "        num_cameras = read_next_bytes(fid, 8, \"Q\")[0]\n",
    "        for _ in range(num_cameras):\n",
    "            camera_properties = read_next_bytes(\n",
    "                fid, num_bytes=24, format_char_sequence=\"iiQQ\")\n",
    "            camera_id = camera_properties[0]\n",
    "            model_id = camera_properties[1]\n",
    "            model_name = CAMERA_MODEL_IDS[camera_properties[1]].model_name\n",
    "            width = camera_properties[2]\n",
    "            height = camera_properties[3]\n",
    "            num_params = CAMERA_MODEL_IDS[model_id].num_params\n",
    "            params = read_next_bytes(fid, num_bytes=8*num_params,\n",
    "                                     format_char_sequence=\"d\"*num_params)\n",
    "            cameras[camera_id] = Camera(id=camera_id,\n",
    "                                        model=model_name,\n",
    "                                        width=width,\n",
    "                                        height=height,\n",
    "                                        params=np.array(params))\n",
    "        assert len(cameras) == num_cameras\n",
    "    return cameras\n",
    "\n",
    "\n",
    "def read_extrinsics_text(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                image_id = int(elems[0])\n",
    "                qvec = np.array(tuple(map(float, elems[1:5])))\n",
    "                tvec = np.array(tuple(map(float, elems[5:8])))\n",
    "                camera_id = int(elems[8])\n",
    "                image_name = elems[9]\n",
    "                elems = fid.readline().split()\n",
    "                xys = np.column_stack([tuple(map(float, elems[0::3])),\n",
    "                                       tuple(map(float, elems[1::3]))])\n",
    "                point3D_ids = np.array(tuple(map(int, elems[2::3])))\n",
    "                images[image_id] = Image(\n",
    "                    id=image_id, qvec=qvec, tvec=tvec,\n",
    "                    camera_id=camera_id, name=image_name,\n",
    "                    xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_colmap_bin_array(path):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_dense.py\n",
    "\n",
    "    :param path: path to the colmap binary file.\n",
    "    :return: nd array with the floating point values in the value\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as fid:\n",
    "        width, height, channels = np.genfromtxt(fid, delimiter=\"&\", max_rows=1,\n",
    "                                                usecols=(0, 1, 2), dtype=int)\n",
    "        fid.seek(0)\n",
    "        num_delimiter = 0\n",
    "        byte = fid.read(1)\n",
    "        while True:\n",
    "            if byte == b\"&\":\n",
    "                num_delimiter += 1\n",
    "                if num_delimiter >= 3:\n",
    "                    break\n",
    "            byte = fid.read(1)\n",
    "        array = np.fromfile(fid, np.float32)\n",
    "    array = array.reshape((width, height, channels), order=\"F\")\n",
    "    return np.transpose(array, (1, 0, 2)).squeeze()\n",
    "    \n",
    "def readColmapCameras(cam_extrinsics, cam_intrinsics, images_folder):\n",
    "    \"\"\"\n",
    "    From https://github.com/graphdeco-inria/gaussian-splatting/blob/main/scene/dataset_readers.py\n",
    "    \"\"\"\n",
    "\n",
    "    cam_infos = []\n",
    "    for idx, key in enumerate(cam_extrinsics):\n",
    "        sys.stdout.write('\\r')\n",
    "        # the exact output you're looking for:\n",
    "        sys.stdout.write(\"Reading camera {}/{}\".format(idx+1, len(cam_extrinsics)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        extr = cam_extrinsics[key]\n",
    "        intr = cam_intrinsics[extr.camera_id]\n",
    "        height = intr.height\n",
    "        width = intr.width\n",
    "\n",
    "        uid = intr.id\n",
    "        R = np.transpose(qvec2rotmat(extr.qvec))\n",
    "        T = np.array(extr.tvec)\n",
    "\n",
    "        if intr.model==\"SIMPLE_PINHOLE\":\n",
    "            focal_length_x = intr.params[0]\n",
    "            FovY = focal2fov(focal_length_x, height)\n",
    "            FovX = focal2fov(focal_length_x, width)\n",
    "        elif intr.model==\"PINHOLE\":\n",
    "            focal_length_x = intr.params[0]\n",
    "            focal_length_y = intr.params[1]\n",
    "            FovY = focal2fov(focal_length_y, height)\n",
    "            FovX = focal2fov(focal_length_x, width)\n",
    "        else:\n",
    "            assert False, \"Colmap camera model not handled: only undistorted datasets (PINHOLE or SIMPLE_PINHOLE cameras) supported!\"\n",
    "\n",
    "        image_path = os.path.join(images_folder, os.path.basename(extr.name))\n",
    "        image_name = os.path.basename(image_path).split(\".\")[0]\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        cam_info = CameraInfo(uid=uid, R=R, T=T, FovY=FovY, FovX=FovX, image=image,\n",
    "                              image_path=image_path, image_name=image_name, width=width, height=height)\n",
    "        cam_infos.append(cam_info)\n",
    "        \n",
    "    sys.stdout.write('\\n')\n",
    "    return cam_infos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
